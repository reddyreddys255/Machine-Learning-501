{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction \n",
    "We will be using the wine quality dataset for these exercises.  This data set contains various chemical properties of wine, such as acidity, sugar, pH, and alcohol.  It also contains a quality metric (3-9, with highest being better) and a color (red or white).  The name of the file is `Wine_Quality_data.csv`\n",
    "\n",
    "### Prequisites \n",
    "Install pydotplus and seaborn in your own virtual environment \n",
    "\n",
    "`!pip install pydotplus\n",
    "!pip install seaborn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os \n",
    "data_path = ['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "filepath = os.sep.join(data_path + ['Wine_Quality_Data.csv'])\n",
    "data = pd.read_csv(filepath, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality color  \n",
       "0      9.4        5   red  \n",
       "1      9.8        5   red  \n",
       "2      9.8        5   red  \n",
       "3      9.8        6   red  \n",
       "4      9.4        5   red  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed_acidity           float64\n",
       "volatile_acidity        float64\n",
       "citric_acid             float64\n",
       "residual_sugar          float64\n",
       "chlorides               float64\n",
       "free_sulfur_dioxide     float64\n",
       "total_sulfur_dioxide    float64\n",
       "density                 float64\n",
       "pH                      float64\n",
       "sulphates               float64\n",
       "alcohol                 float64\n",
       "quality                   int64\n",
       "color                    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the color feature to an integer. This is a quick way to do it using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['color'] = data.color.replace('white', 0).replace('red', 1).astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "* Use `StratifiedShuffleSplit` to split data into train and test sets that are stratified by wine quality. If possible, preserve the indices of the split for question 5 below. \n",
    "* Check the percent composition of each quality level for both the train and test data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fixed_acidity',\n",
       " 'volatile_acidity',\n",
       " 'citric_acid',\n",
       " 'residual_sugar',\n",
       " 'chlorides',\n",
       " 'free_sulfur_dioxide',\n",
       " 'total_sulfur_dioxide',\n",
       " 'density',\n",
       " 'pH',\n",
       " 'sulphates',\n",
       " 'alcohol',\n",
       " 'quality']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ALL data coluns except for color \n",
    "feature_cols = [x for x in data.columns if x not in 'color']\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Split the data into two parts with 1000 points in the test data \n",
    "# This creates a generator \n",
    "strat_shuff_split = StratifiedShuffleSplit(n_splits = 1, # number of splitting iterations\n",
    "                                           test_size = 1000, \n",
    "                                           random_state = 42)\n",
    "\n",
    "# Get the index values from the generator \n",
    "train_idx, test_idx = next(strat_shuff_split.split(data[feature_cols], \n",
    "                                                   data['color']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the data sets \n",
    "X_train = data.loc[train_idx, feature_cols] # or data.iloc[train_idx, :-1]\n",
    "y_train = data.loc[train_idx, 'color'] # or data.iloc[train_idx, -1:]\n",
    "\n",
    "X_test = data.loc[test_idx, feature_cols]\n",
    "y_test = data.loc[test_idx, 'color']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check the percent composition of each quality level in the train and test data sets. The data set is mostly white wine, as can be seen below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.753866\n",
       "1    0.246134\n",
       "Name: color, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize = True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.754\n",
       "1    0.246\n",
       "Name: color, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize = True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3627</th>\n",
       "      <td>8.9</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.34</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.037</td>\n",
       "      <td>33.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.99620</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.45</td>\n",
       "      <td>9.7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.34</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.038</td>\n",
       "      <td>30.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.99540</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.44</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5055</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.042</td>\n",
       "      <td>60.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.52</td>\n",
       "      <td>10.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372</th>\n",
       "      <td>6.1</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.30</td>\n",
       "      <td>16.7</td>\n",
       "      <td>0.039</td>\n",
       "      <td>49.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.99985</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.45</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.073</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.99690</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "3627            8.9              0.21         0.34             7.1      0.037   \n",
       "1932            6.5              0.28         0.34             9.9      0.038   \n",
       "5055            6.0              0.39         0.13             1.2      0.042   \n",
       "2372            6.1              0.27         0.30            16.7      0.039   \n",
       "158             7.1              0.68         0.00             2.2      0.073   \n",
       "\n",
       "      free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "3627                 33.0                 150.0  0.99620  3.10       0.45   \n",
       "1932                 30.0                 133.0  0.99540  3.11       0.44   \n",
       "5055                 60.0                 172.0  0.99114  3.06       0.52   \n",
       "2372                 49.0                 172.0  0.99985  3.40       0.45   \n",
       "158                  12.0                  22.0  0.99690  3.48       0.50   \n",
       "\n",
       "      alcohol  quality  \n",
       "3627      9.7        6  \n",
       "1932      9.8        5  \n",
       "5055     10.6        5  \n",
       "2372      9.4        5  \n",
       "158       9.3        5  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "* Fill a decision tree classifier with no set limits on maximum depth, features, or leaves. \n",
    "* Determine how many nodes are present and what the depth of this (very large) tree is. \n",
    "* Using this tree, measure the prediction error in the train and test data sets. What do you think is going on here based on the differences in prediction error? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state = 42)\n",
    "dt = dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of nodes and the maximum actual depth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171, 22)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.tree_.node_count, dt.tree_.max_depth "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 161 nodes and a maximum depth of 19.  A function to return error metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def measure_error(y_true, y_pred, label): \n",
    "    return pd.Series({'accuracy': accuracy_score(y_true, y_pred),\n",
    "                      'precision': precision_score(y_true, y_pred), \n",
    "                      'recall': recall_score(y_true, y_pred), \n",
    "                      'f1': f1_score(y_true, y_pred)}, \n",
    "                      name = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.999818</td>\n",
       "      <td>0.984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.999631</td>\n",
       "      <td>0.967611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.999261</td>\n",
       "      <td>0.963710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train      test\n",
       "accuracy   0.999818  0.984000\n",
       "f1         0.999631  0.967611\n",
       "precision  0.999261  0.963710\n",
       "recall     1.000000  0.971545"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# error on the training and test data sets \n",
    "\n",
    "y_train_pred = dt.predict(X_train)\n",
    "y_test_pred = dt.predict(X_test)\n",
    "\n",
    "train_test_full_error = pd.concat([measure_error(y_train, y_train_pred, 'train'), \n",
    "                                   measure_error(y_test, y_test_pred, 'test')], \n",
    "                                   axis = 1)\n",
    "\n",
    "train_test_full_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The decision tree predicts a little better on the training data than the test data, which is consistent with (mild) overfitting. \n",
    "* Also notice the perfect recall score for the training data. \n",
    "* In many instances, this prediction difference is even greater than that seen here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 \n",
    "* Using gridsearch with cross validation, find a decision tree that performs well on the test data set. Use a different variable name for this decision tree model than in question 3 so that both can be used in question 6. \n",
    "* Determine the number of nodes and the depth of this tree. \n",
    "* Measure the errors on the training and test sets as before and compare them to those from the tree in question 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'max_depth': range(1, dt.tree_.max_depth + 1, 2), \n",
    "              'max_features': range(1, len(dt.feature_importances_) + 1)}\n",
    "\n",
    "GR = GridSearchCV(DecisionTreeClassifier(random_state = 42), \n",
    "                  param_grid = param_grid, \n",
    "                  scoring = 'accuracy', \n",
    "                  n_jobs = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GR = GR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GR.best_estimator_.tree_.node_count, GR.best_estimator_.tree_.max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of nodes is 119 and the maximum depth of the tree is 9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.995816</td>\n",
       "      <td>0.989000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.991440</td>\n",
       "      <td>0.977505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.998501</td>\n",
       "      <td>0.983539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.984479</td>\n",
       "      <td>0.971545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train      test\n",
       "accuracy   0.995816  0.989000\n",
       "f1         0.991440  0.977505\n",
       "precision  0.998501  0.983539\n",
       "recall     0.984479  0.971545"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred_gr = GR.predict(X_train)\n",
    "y_test_pred_gr = GR.predict(X_test)\n",
    "\n",
    "train_test_gr_error = pd.concat([measure_error(y_train, y_train_pred_gr, 'train'), \n",
    "                                 measure_error(y_test, y_test_pred_gr, 'test')], \n",
    "                                 axis = 1)\n",
    "train_test_gr_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test scores are slightly better than the previous ones, it seems like the 1st example is actually overfitting the data very slightly more than the 2nd decision tree (which has less nodes and less depth). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 \n",
    "* Re-split the data into X and y parts, this time with `residual_sugar` being the predicted (y) data. *Note*: if the indices were preserved from the `StratifiedShuffleSplit` output in question 2, they can be used again to split the data. \n",
    "* Using grid search with cross validation, find a decision tree **regression model** that performs well on the test data set. \n",
    "* Measure the errors on the training and test sets using mean squared error. \n",
    "* Make a plot of actual vs predicted `residual_sugar`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols = [x for x in data.columns if x != 'residual_sugar']\n",
    "\n",
    "X_train = data.loc[train_idx, feature_cols]\n",
    "y_train = data.loc[train_idx, 'residual_sugar']\n",
    "\n",
    "X_test = data.loc[test_idx, feature_cols]\n",
    "y_test = data.loc[test_idx, 'residual_sugar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Fit decision tree regressor to get max depth and max number features \n",
    "dr = DecisionTreeRegressor().fit(X_train, y_train)\n",
    "\n",
    "# Create a range of depth and number of features for parameter grid to test \n",
    "param_grid = {'max_depth': range(1, dr.tree_.max_depth + 1, 2), \n",
    "              'max_features': range(1, len(dr.feature_importances_) + 1)}\n",
    "\n",
    "# Tune depth and feature number hyperparameters using GridSearchCV\n",
    "GR_sugar = GridSearchCV(DecisionTreeRegressor(random_state = 42), \n",
    "                        param_grid = param_grid, \n",
    "                        scoring = 'neg_mean_squared_error', \n",
    "                        n_jobs = -1) \n",
    "\n",
    "GR_sugar = GR_sugar.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2743, 13)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GR_sugar.best_estimator_.tree_.node_count, GR_sugar.best_estimator_.tree_.max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of nodes is 1363 and the maximum depth of the tree is 11.  This tree has lots of nodes, which is not surprising given the continuous data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>2.85486</td>\n",
       "      <td>0.326946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        test     train\n",
       "MSE  2.85486  0.326946"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "y_train_pred_gr_sugar = GR_sugar.predict(X_train)\n",
    "y_test_pred_gr_sugar = GR_sugar.predict(X_test)\n",
    "\n",
    "train_test_gr_sugar_error = pd.Series({'train': mean_squared_error(y_train, y_train_pred_gr_sugar), \n",
    "                                       'test': mean_squared_error(y_test, y_test_pred_gr_sugar)}, \n",
    "                                      name = 'MSE').to_frame().T\n",
    "\n",
    "train_test_gr_sugar_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used mean squared error because it is continuous data.  These are the train and test errors for the data sets. The test error is much higher than the training error, which leads me to believe that this model is overfitting the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('white')\n",
    "sns.set_palette('dark')\n",
    "\n",
    "% matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAF2CAYAAABj+Z+GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X2cFNWd7/FPzwwzw25gRCOYQRCzxuNDYLNiBq8J6n2h\nycZdXySyD0yM1yH36o2Bwbhm9YIQNezCuru6LgyYrNlAggaM8YGXd3GDsusD6wrReHUMciQqCkFB\nWcKDwjAPff/o7rGnp6q6qrurp6vr+369fGW6urrrTA2pX9XvnPM7iWQyiYiIxFfNUDdARESGlgKB\niEjMKRCIiMScAoGISMwpEIiIxJwCgYhIzNWF9cXGmFrgHsAAvcAsoAl4FNie3u1ua+39YbVBRETy\nCy0QAJcBWGs/Z4y5CLiTVBC401p7R4jHFRGRABJhTigzxtRZa3uMMVcBnyP1ZGBIBaDtwLestYdC\na4CIiOQVaiAAMMb8CPgK8CfAWOBla+0LxpibgVHW2m+7fK4B+CzwDqkAIiIi+dUCnwB+Ya3t8vOB\nMFNDAFhrrzLG3ARsBs631v4m/dbDwDKPj34WeCbs9omIVKmpwCY/O4bZWXwlcLK1dgnwIdAHPGSM\nabfWbgGmAS94fMU7APfddx8nnXRSWM0UEakq7777LldccQWkr6F+hPlE8BCw0hjzNDAM+BawE+gw\nxhwD3gWu8fh8L8BJJ53EySefHGIzRUSqku+UemiBwFr7AfBnDm+dH9YxRUQkOE0oExGJOQUCEZGY\nUyAQEYk5BQIRkZhTIBARiTkFAhGJhbXrOpl0yQrqJtzGpEtWsHZd51A3CYDrr7+ezZs38/TTT3P/\n/e41OO+//366u7tDaUPoM4tFRIba2nWdtM55sP9157a9/a9nTp84VM0a4IILLvB8//vf/z5f/vKX\nQzm2AoGIVL3FHc7VapYs31RUIHjooYfYuHEjhw8fZv/+/cyePZtly5YxYcIE6uvrue2227j55pvZ\nv38/AAsWLMAYw3333ccDDzzAiSeeyL59+/q/64033uDb3/42K1as4IknnqC3t5fW1lZqa2t57733\nuP7661mxYkXB7XWjQCAiVW/r9vcCbQ/iww8/ZOXKlfzXf/0Xf/qnf0pvby/f/OY3Oeuss/i7v/s7\nzjvvPL761a+yY8cO5s2bxz/90z/x4x//mEcffZREIsHll18+sE1bt/L000/zwAMPcOzYMe644w5u\nvvlm7r77bv7hH/6h6PY6USAQkap31qdOpHPbXsftxfrsZz9LTU0NH//4xxk5ciSvv/46p556KgCv\nvfYazz33HI899hgABw8e5I033uC0006jvr4egEmTJg34vjfffJNJkyZRW1vL8OHDWbBgQdFtzEed\nxSJS9ebPmeq4fd7szxf93b/61a8AeP/99zl8+DAnnHACNTWpS+snP/lJ2traWL16NXfddReXXXYZ\n48aN49e//jVHjx6lt7eXV199dcD3ffKTn2Tr1q309fXR3d3NrFmzOHbsGIlEgr6+vqLb60RPBCJS\n9TL9AEuWb2Lr9vc461MnMm/250vSUfz+++9z1VVXcejQIW655RZuvfXW/ve+8Y1vcPPNN/PTn/6U\nw4cPM2fOHI4//niuu+46Zs6cyfHHH8/w4cMHfN+ZZ57J1KlTaW1tpa+vj9bWVurr6zn33HO55ppr\n+PGPf0wikSi63dlCX5imUMaYCcCbGzduVPVREalI2R28lWLXrl1MmzYN4FRr7Q4/n1FqSEQk5pQa\nEhEpUO6In6jSE4GISMwpEIiIxJwCgYhIzCkQiIjEnAKBiEjMKRCIiMScAoGISMwpEIiIxJwCgYhI\nzCkQiIiUSKUuh5mPSkyIiJRAFJbDdKMnAhGREvBaDrPSKRCIiJRAmMthhk2BQESkBNyWvSzFcphh\nUyAQESmBMJfDDJs6i0VESiDM5TDDpkAgIlIiM6dPjMSFP5dSQyIiMadAICIScwoEIiIxp0AgIhJz\nCgQiIjGnQCAiEnMKBCIiMRfaPAJjTC1wD2CAXmAWkABWAUngFWC2tbYvrDaIiEh+YT4RXAZgrf0c\n8B3gzvR/C6y1U0kFhekhHl9ERHwILRBYax8Brkm/PAXYA0wGnkpvewy4OKzji4iIP6H2EVhre4wx\nPwKWAT8DEtbaZPrtQ0BTmMcXEZH8Qu8sttZeBZxOqr9geNZbI4Dfhn18ERHxFlogMMZcaYyZl375\nIdAHPG+MuSi97UuA85I+IiJSNmFWH30IWGmMeRoYBnwLeBW4xxhTn/75ZyEeX0REfAgtEFhrPwD+\nzOGtC8M6poiIBKcJZSIiMadAICIScwoEIiIxp0AgIhJzCgQiIjGnQCAiEnMKBCIiMadAICIScwoE\nIiIxp0AgIhJzCgQiIjGnQCAiEnMKBCIiMadAICIScwoEIiIxp0AgIhJzCgQiIjGnQCAiEnMKBCIi\nMadAICIScwoEIiIxp0AgIhJzCgQiIjGnQCAiEnMKBCIiMadAICIScwoEIiIxp0AgIhJzCgQiIjGn\nQCAiEnMKBCIiMadAICIScwoEIiIxp0AgIhJzCgQiIjGnQCAiEnMKBCIiMadAICISc3VhfKkxZhjw\nQ2AC0AD8FbALeBTYnt7tbmvt/WEcX0RE/AslEABfA/ZZa680xpwAvAh8F7jTWntHSMcUEZEChBUI\nHgB+lvW6B5gMGGPMdFJPBd+y1h4K6fgiIuJTKH0E1trD1tpDxpgRpALCAmAL8JfW2guAN4Bbwji2\niIgEE1pnsTFmHPDvwGpr7U+Ah621L6Tffhj4g7COLSIi/oUSCIwxY4ANwE3W2h+mN//cGNOS/nka\n8ILjh0VEpKzC6iOYD4wCFhpjFqa3/QVwlzHmGPAucE1IxxYRkQBCCQTW2uuA6xzeOj+M44mISOE0\noUxEJOYUCEREYk6BQEQk5hQIRERiToFARCTmFAhERGJOgUBEJOYUCEREYk6BQEQk5hQIRERiToFA\nRCTmFAhERGJOgUBEJOYUCEREYk6BQEQk5hQIRERiToFARCTmFAhERGJOgUBEJOYUCEREYk6BQEQk\n5hQIRCrQ2nWdTLpkBXUTbmPSJStYu65zqJskVaxuqBsgIgOtXddJ65wH+193btvb/3rm9IlD1Syp\nYnoiEKkwizuecdy+ZPmmMrdE4kKBQKTCbN3+XqDtIsVSIBCpMGd96sRA20WKpUAgUmHmz5nquH3e\n7M+XuSUSF+osFqkwmQ7hJcs3sXX7e5z1qROZN/vz6iiW0CgQiFSgmdMn6sIvZaPUkIhIzCkQiIjE\nnAKBiEjMKRCIiMScAoGISMwpEIiIxJwCgYhIzCkQiIjEnAKBiEjMKRCIiMRcKCUmjDHDgB8CE4AG\n4K+ArcAqIAm8Asy21vaFcXwREfEvrCeCrwH7rLVTgS8BHcCdwIL0tgQwPaRjSwi0dKJI9Qqr6NwD\nwM+yXvcAk4Gn0q8fA74APBzS8aWEtHSiSHUL5YnAWnvYWnvIGDOCVEBYACSstcn0LoeApjCOLaWn\npRNFqltoncXGmHHAvwOrrbU/AbL7A0YAvw3r2FJaWjpRpLqFEgiMMWOADcBN1tofpje/aIy5KP3z\nlwDn20ypOFo6sfTc+lzUFyNDIaw+gvnAKGChMWZhett1wFJjTD3wKgP7EKSCzZ8zdUAfQYaWTiyM\nW5/Ls8/vZNmqLYO2g/piJFyhBAJr7XWkLvy5LgzjeBIuLZ1YWm59Lves+aXj9iXLN+lcS6i0VKX4\noqUTS8etb+VoV0+g/UVKRTOLRcrMrW+lscH5vkx9MRI2BQKRIvjp3J27cD3DT1tEYtytDD9tEc2j\nRzh+19Wt5zhuz+6LUWeyhMFXIDDGnO2w7bzSN0ckOjKdvp3b9tLbm+zv3M2+OM9duJ5lq7ZwtKsX\ngKNdvfz86df54gW/x6Qzx1BXV8OkM8ewpmMGSxddypqOGYO2Z1Jyfo4nUgjPPgJjzOeAWuAHxpj/\nSao0ROZz3wNOD7d5IpXLa6Jd5uJ9z5oXHPd5avNbHPn1gkHbvfpi/BxPpBD5OosvITXS5xPAd7O2\n9wDfD6tRIlHgZ6Jd5kkgl1vHcLHHEymEZyCw1t4KYIy5Elhjre1JVxatt9Z+UIb2iVSssz51Ip3b\n9jpuz2hsqHUMBm4dw8UeT6QQfjuLu4AX0z+PB7YZY1Q9VGJt/pypjtuzO3evbp3suI9bx3CxxxMp\nhN9AsAC4GMBa+zqpSqK3hdUokSiYOX2iZ+cuwNJFl9Le1tL/BNDYUEd7WwtLF10ayvFECpFIJpN5\ndzLGbLPWnpGz7SVr7e+H1TBjzATgzY0bN3LyySeHdRgRkaqya9cupk2bBnCqtXaHn8/4TVRuMsas\nAe4jtcLYnwP/WUgjRarF2nWdLO54pr/sRvPoETy1eQdHu3ppbKjl6tbJBd35i5Sb30AwG2gH/jfQ\nDTwNrAirUSKVzqlwXHZH7tGu3v4CcgoGUuk8+wiMMSelfxwD/JRUQPgW8BBwktvnRKqd25j+XG6F\n5EQqSb4ngh8Af0xqickkqQll2f/7yVBbJ1Kh/I7dL2S+gEi55ZtH8Mfp/z21PM2RapSbS58/Z2rk\nR7q4jenPlUikfv+o/75S3fKVmPih1/vW2q+XtjlSbap14Xu3xXpyJZNUxe8r1S3fPIKn0v+NAJqB\nfyO1BOUoH58VqdqF74Ne1KP++0p187yYW2t/ZK39EanZxJdaa++11q4FZgBnlaOBEm2lqo/jt/xy\nOcs0j2se6Xtf1QOSSub3rr4JOD7r9RjgY6VvjlSbUix877f8cinKNAcJJF/+whmu7+VSPSCpZH4D\nwV8DLxtjHjDGPAg8T6rshIinUtTH8ZteKjYNFTSQPLJhm6/vBdUDksrma0KZtXa1MeYJ4HxSw0av\ntdbmHzIhsVeKhe/9ppcKTUPNXbiee9a84FoyOhNIblz8ODt3HwRSaaHMz04mnTmm4N9XpNx8BQJj\nTD0wCziD1Azj64wxf2OtPRZm46Q6FLvwvd/yy4WUac6sIOblFbt30AghryAA8NKGaz3fF6kkflND\ny0n1CZxDqsTEaYDn0FKRUvGbXiokDeW2gli2vr78hRmzjR/bFGh/kaHmNxBMttbOB7qttR8CVwGf\nCa9ZIh/xW365kDLNbumgYtw+7+KSf6dImPwWnUum00OZW6OPZ/0sEqrcmcleOfegaSi3FcT8Gt/c\nxHFNjeoPkEjzGwjuAp4ATjLG3AV8BS1MI2UQ9szkq1sn5+0j8HL7/It14ZfI85saegz4BqlhpG8A\nl1lr1UcgoQt7ZrLbCmKNDbWenxs/tkmrg0nV8PtE8Iy19kxga5iNEclVqpnJXpYuutRxzQCnJ4VC\nl5kUqWR+A8FLxpj/AWwGjmQ2WmvfDqVVImmFDAkthczF/p41v+RoVw+NDXVc3XqOgoBUJb+BYArQ\nQmodggytRyChc6vyWY6Zum5PCiLVJl8Z6mbg74FDwLPA/7HW/rYcDROB0sxMFhFv+Z4IVgKdpBat\n/xPgTkBrEEhZFTszWUS85Rs1NNZa+21r7b8A15BKEYkMUs7yzyJSWvmeCPprCVlru40xqi0kg1TS\nKmTZBeQaG2q5unUy5587jsUdz/CK3UtDfS3Huvs4+/QT+0tS+FlGsxqX2xTJCLrKmGYTV5Egd/Fe\n+5ZjFTI/bc0UkMvMFD7a1cuyVVv6S0snk6ltfX0flZgu1zoHIpUs3xPB2caYN7Jej02/TgBJa61G\nDZVYue48g9zF59s37LH+XseHj+7ogxaHc7Nk+aYB58Ar0OmpQKpBvkBwellaIUB5UyxBLm759g06\n1j9osHM7/k2Ln+Dt3QdcP1eoUq1zIBIVnoHAWvtWuRoi5b3zDHJxy7dvkLH+hQQ7t+OHEQSgNOsc\niERJ0D4CCVE57zyDrCWcb98g5Z8L6U8o9wW3FOsciERJqIHAGDPFGPNk+udzjDG/McY8mf7vz8M8\ndhSVYqF3v4Jc3PzsO3P6RF7acC3db36HlzZcG/ju3ivYuR1/XPNI18/kk0jAmo4ZJVvnQMNnJcr8\nlpgIzBhzI3Al8EF60znAndbaO8I6ZtSVs5xCkBm7pZzdW0iaxe34gOP58mPOVS393+vn9/Ca1FZJ\nw2dFChFaIABeBy4HVqdfTwaMMWY6sB34lrX2UIjHj5xyl1MIMmO3VLN7Cw12XscP2ml8wqjhJa0h\npFFFEnWhpYastQ+SWt84Ywvwl9baC0itaXBLWMeOMr8plkrhlhJx217IcpJex7xx8eN8cCTYPMcD\nh7oC7Z9PmH07SjlJOYT5RJDr4ayCdQ8Dy8p47Ko1lDNe3VIizz6/c0At/9xUSTFPF7nH3Ln7YODv\nKHWfS1ijipRyknIp56ihnxtjWtI/TwNeKOOxq9JQz3h1S4ncs+aXjtv9zDTOdwfsdswgSt3nEtao\nonLM2BaB8j4RXAt0pOsVvUuqiJ0UYahz026pj6NdPYH2z/BzBxw03VKOxeXD6tvRRDYpl1ADgbV2\nB3Be+udfAueHeby4GeoLhVtKpLGhzjEY5EuV+Alsbsd0U67F5cMola2JbFIumlAWYeWcd+DELSVy\ndes5jtvzpUr8BLaE4x7Oor64vCaySbkoEERYmBcKP6NV3EYALV10aUEjg/IFtrkL1/Oyz6eBxoa6\nSAcBKM0IKxE/EslkZVaWNsZMAN7cuHEjJ5988lA3p2KtXddZ8tx0bq4+o6Ym0V/Hv1QXo+xRT81j\nRjiOAqqpSTCqqZF9+4/4/t72thbHuQJaV0Cq3a5du5g2bRrAqen0fF7l7CyWEISRm3bL1WfX8c8c\nuxhuQ0HHj21i1zsH+8tK9/UlfQeBxoY6rm49xzUIaDimyGBKDUVIuSYX+elszgxh9DuhbO7C9YP2\ncws47+w5VPDaAke7eli2agsfn3R7f1v+8IrVJMbd6lqOonXOg9Sf+l3mLlxf0DFFok6poYhwS9eE\nkTOedMmKvCNz6upqWH3XVxzb1N7WMmBCmZuamkTJFpNxM+mM0b77FcA9pSQSFYWkhvREEBE3Ln7c\ncXsYk4vcOqGz9fT0MeuGRxzfc5tQlqt+WG2gdhUiSBAA/20XqSYKBBGwdl2naymFMOYMZI9Wqalx\nH7CZWRt48HbnCWW5jnU7f34o+W27SDVRIIgAr7IKYc0ZyBS/633rlv6g4Fdjg78xCJ82owcMj/T7\nuTBVQhtEyk2BIAK87vrLMbkoExRqa/1N53KbUJYrM9Q1U2115R3Ti2mmo0lnjA60v9+2i1QTBYII\ncLvrH9/cVNZhj27taGyoyzuhrL2txfdKYMPqvP9Ztre1ML65yXOfE0YNZ03HDF56/Jt88YLfy/u7\nDaurUUexxJaegyPAbTGX2+dfXBHtWHnHdMeLeu62zJDRX722tz/dldnHz8Qy+GhUT5AL9r/ed6Um\nkol4iGUgiNpFodwrl4XRDq/JXIDjxLITRg3vn0g2fmwTt88rrICcJpKJeIvdPIJyjseXj7jNTZh0\n5hiSyaTrey9tuDbUY5fi+0UqieYR+KDFPso3Qzn7OG4T1F5+dQ+vuLz3it0baBlMN796TXX9RbzE\nLjU01DX8h1q50iRuT15O3J5JM7WNwP8ymE7tcJu9rLr+IimxeyIY6hr+Q61cT0SlWFLSSdBlML3a\nobr+IimxCwRxX+yjXE9ExXzfCaOGu85oDroMptv2mppERfQJlStNJ+IldoEg7ot9lOuJqJjv27f/\nCL8zfJjje24zf4P+Xp82wSaahSGTPuvctpfe3o9KfCsYSLnFLhAAA2azvrTh2tgEASjfE5GfwnVe\nDn9wzHF70GUwK/kJUAMXpFLEMhDEWSmfiLzSGjOnT2Rc88ii2jq+uanoZTAr+Qkw7gMXpHLEbtSQ\nlGZVM7fRR88+v5Mnn9vB1u3vcdzIxqKO8fbuA7y9+wAA+w98tEKZV/vdJgtWwoU/11mfOtFxWG1c\nBi5I5dATgbjyuuN3S2ssW7WlP+cdZI3hfHbuPpg3fx61nHslp60kXhQIxFG+i+pQpS+88udRy7lX\nctpK4kWpIXHkdVGdOX2ia1rDj0QC5lzVwvnnjvM96SzDKwBFMedeqWkriRc9EVS5Qsep57uoXnTe\nhILblEzSPzt4YsD1Arzy53GfLChSKAWCEqq0yUHF5My9Lqpr13X6Wpw+nyXLNwUeZuqVP3cLThdO\nOSXQMUTiRoGgRCqxo7KYnLlXR2apykds3f7egDy5l/Fjm/Lmz598bofj9qc2v1VMM0WqXqwCQZh3\n7JXYUVlMznzm9Im0t7X0z+RtbKijva2FmdMnulbzDKppREP/sfIthZnZ10sU+whEKkFsOovDrrpZ\niRchv+PUM2PvX7F7aaiv5Vh3H2NPGrhK2NGunv50kFs1z6D27T9Czfhb+bQZzfw5Uz07oP38vbx+\n36gtRiRSTrF5Igj7jr0SOyrd0jv7DxwZUNs/k9JKJuFoVy99fUnXpSLdqn8WKpn86CLvpwPa6+/l\n9vteOOWUikvbiVSS2ASCsO/YK3FyUCb/nrvQe/bkrKD5frfqn17y5f8zntr8Vt7+Aq+/l9u4fLe+\ng0qdXyBSbrEJBGHfsVfq5KCZ0yfSNNI5v55ZezhMmeUgGxtq8+6b6Tx+acO1rsNK8/29nAoKVmLa\nTqSSxCYQlOOOvVKrmnot1Rh26ipzfq9unZx33+y2lPLvVYlpO5FKEptAUKl37GHLt1RjseWi3eSe\n36WLLqW9rYVhde7/5LIv8qX8e1Vi2k6kksRm1BBU7nT+MEe05FuqMXOcJcs38fKre0pyzJqaBC9t\nuHbQ9vPPHec4EW382CZun3fxoN+5VH+v7N8xc46zf3eRuItVIKhEQzWsNXupxpnTJ/Ls8ztLFgjq\nhzn3B7gFpeNGNoZ+Ua7UmwCRShCb1FClGqphrblLNX7v3udLcjyA7u5ex+3qtBWpTKEGAmPMFGPM\nk+mfTzPGbDLGPGOMudsYoyBEZQxrXbuuk+6evpIcD+Bsl/WA1WkrUplCuxgbY24EfgBklqm6E1hg\nrZ0KJIDpYR17qBRSwqKYi6PT8eYuXM/w0xaRGHcrw09bxLPP78zb6VpI7aDxzanaP07mzf68Y9u8\nJnxVUrE+kbgJs4/gdeByYHX69WTgqfTPjwFfAB4O8fhlVWiuf/6cqY41+fONaPE6XsbRrl6WrdrC\nT9Z10rHo0kHtyHRSF7KuwPQvGNdOWMCxbWs6ZrCmY8aA/S+ccsqADuRS95GISH6hBQJr7YPGmAlZ\nmxLW2sw4xkNA0+BPRVe+hVzcFDqiJchd/L79RwZcXNeu6+TGxY+7lpHwY9mqLZx/7jjHTthJl6xw\n/MyS5ZsGza/w2leBQKQ8yjlqKDsJPQL4bRmPHbpCcv25w0ZX3/UV3xe/QvoQMh3QflcFa29LrSI2\n64Z1jqUl3C7WQc6FOpBFhl45O2xfNMZclP75S0BpitpXiKC5/mLXLyikg3Xr9ve4cfHjvvdftmoL\nizue4VjAUUBBzoU6kEWGXjkDwQ3AbcaY/wTqgZ+V8dihCzp7tdhho4XMCK6rrQmcDurcttd1ZnLz\nmBGB2uZ0Lko167fSVocTiZJQU0PW2h3AeemfXwMuDPN45eQ0Gzi3I9Qr119MSmTuwvV8795fuL6f\nSKTKO+cqpHKol3f2HGLtuk7HGcEANy1+grd3HwBgXPNIx+8oxazfsCfliVQ7zSwugNuFZ03HDMfS\nCk4KXURl7sL1edcLdgoCYeju6fO84GaCAHxU+tpp32Jn/RbaUS8iKVU5qSvsNEEpZgMXuojKPWte\nCN7gkDn93sWco6B/P3U4ixSn6gJBORaRL8WFp9BFVI52OXfcDqVSjgYq5O+nDmeR4lRdICjHIvKl\nuvAUsoiKnwVeyq2Uo4EK+fupzLRIcaouEJQjTRDmhcfrAjp34XrXgm5Daf+BI4PSOIWeo0L+fnFd\na0KkVKqus9irE7ZUwqxv71Zy4hMnfsy1k7i2NkFvb5l6iDPHrElwXFMj+/Yf6R+S6jRaJ+g5KvTv\npzLTIoWruieCcqUJ/C5LWUjHdfZQy/FjU8Xdntq8w3HfxoY67v3Hywv6HbKdMGr4gLtptzWDGxvq\nWNMxg3uXXs6+/Ucc98mkcQpZulNpHpHyq7ongkpajSro+Pbc/QHe/k1qCKZbJ/HRrp5As4Vzfex3\n67nn9ssc2+P0ZLLyjunMnD7RtUYQFJeGq6S/n0hcVF0ggMpJEwQd3+61f2NDrWMwGFYXfLZwtuOb\nhju2xauy6KRLVnhWLC02DVcpfz+RuKi61FAlCdrx6bX9wikTHN8rdkGZt3cfcE1X5aZ2gP6hnV6U\nxhGJFgWCEAUdQum1fffeQyVrVy6/Q2v9lL4+YZTzE4aIVC4FghAF7fj02j/MWbJ+v9vPfgcOdRXb\nHBEpMwWCEAUZ3/6HV6zmq+0fdc4mEgzY363SZynkPom4jXTyk/vXbF6R6KnKzuJK4qfj8w+vWM3P\nn359wLZkMjV3oBxpltyF7N1GOrnNcXD7LhGJBgWCEvCqFupk7sL13LPmBY529TKsLkF3j/NksJ8/\n/TqNpy2iK+T6QrNueIQr5j7E2aefyG8PHnXcJ7PMZObnrdvfo3n0CEjA7j2H8g7z9DpHQc+fiJSW\nAkGRgs4VyC0j7RYEMsIOAvDRHAWv0UCZ/oFChnZ6nSNwXug+cywRCZ/6CIoUtEhaJZaR9qOY3L/X\nOSpHkUAR8aYngiKsXdfpehf9inXeXollpP0oJvfvNT8i6bKKjtYSECkfBYICOZWDyFY/zLlctNsM\n4UoyvrmJ45oa+3P2F045hcUdz/C16x7qH72U6Rfwk8/3KiSXTCZDLxIoIt6UGipQvslVXS7rA1/d\nOjmM5pTU7fMv7p9RPG/251m2akv/QjE7dx9k5+6DgRb98ZofoSJzIkMv8oEg7GUp3eRLXbh1AS9d\ndCntbS0Mqxv6Uz+sroZEIlVRtLYm4TjPwc9s4psWP+H5vtd8ilKvJTBU/x5EoizSqaGgI3ZKedxh\ndTX09haW4lm66FKefG5H3po9pTCsroa+viRjTxpJkuSglM7adZ3cuPhxdu4+yMuv7umvZJo5f35y\n9Zl6RV7LIkdxAAAR9klEQVTn3Gu0UamKzA3VvweRqBv629Ii5Btx4nZ3WMxdY+ZiU2yeP8zO0Oy7\n+2Nvfod7l17O27sPDErpzF24ntY5Dw6oXrpz98EB6R6/ufpKGOWjEUgihUm4jdoYasaYCcCbGzdu\n5OSTT3bcp27CbY4rc9XV1bD6rq84dua2t7U4rvRVU5Pg7NOdOz+zJzwNq6vxFQQ+9rvDOHXcKNdJ\nUvlKORdj0plj+id/eR2rsaGOoy59GZnvyNcpnlFXV0P3m98pvNEl4PXvYajbJlIuu3btYtq0aQCn\nWmt3+PlMpJ8IvKp1ut0dfu/e5x239/U5d35mLoSZzlK/TwKHP+ju/4zT97p1kpZC7tOG29OHWxDI\n/kwmh9/Y4J1FrIRRPkGruopISqQDQSHVOv3U789OJfjpLIXU3XWmszN7qUm3783uJC2E1+dyL3xu\nF0Kvi3v2Z2ZOn8jKO6Z7tqcSRvloBJJIYSIdCLxGnBRzF5gdRPzm8lfeMb1/AZfde5zXDsj9rszC\nL2s6ZgRq3/jmJs/P5V743C6QV7ee43qM3O/IPteJRKo6KqSCSXtbS0V0xpZ6BJJIXER61BC4jzjx\nUynTTXYQcZsMlTGsroZvfO1cIJWLz/QjOI0oqqutcRxdM3P6RJ59fqdj34WTd/YeovaU2zj79BNp\nb2vhqc1vOa7vm1vcbuSIRg4c6hqw3/nnjuOmxU/w9u4D/d/v9kST+d7s83q0q4dlq7Zw/rnjKuKC\nq2UuRYKLfCBwkhkSWajsu+F8AaW7p49lq7YMuIi7DSs92tXjOpzxyed2+G5fJr3VuW3vgCC1/8CR\n/p+ditvt23+E9rYWli66tH+708U9M3LIqZ1B12EWkcoX6dSQk0znbpAF3cePbXJNJRSby3eS3VeQ\nGcpaihFE2UM/3Yrb3bPml4O2BRl2GXS9ZRGpfFX3RJCvc7emJsGnzWjHVEo2pxr5X7vuIcfhiUFl\nLppOC9KUwpLlm1xHNzmNFMp3cc8dPuv0xKOROSLRVXWBIN+daf2wWn712t68QcBphuq45pGBnjTc\n9PT0kRh3a9Hf4+YVu9e1uJ3TSCGvonC558It7aWROSLRVXWpoXx3pke7evIWTHN7qkiQKEkbw9bX\nl+TCKRMc33MaKeQ17NLtXGQPl9XIHJFoq7pAEHSiVuucBweVmXB7qti99xBrOmYwvrmpf9v4sU2s\n6ZjBmo4Z/UMqw5YpFuflnfcO097W0v8EkBnmmd1RnOE17NLtXPT09vUPl1UQEIm2qkoNFTpaKLc4\nmVeqxGt44lfbCxuu6ldjQx3Huns547SP9wc8txFNL7+6pz8Fltl3cccz1E24zbHkhdvv5XUuRKQ6\nVE0g8KqJM35sE8lkMm9+f87C9cy64RHXjtbsPHj2GP3Ghlqubp3MyZ8oTR+Cm0xHbyZwtbe1eO6f\nnQLLFqQqp9vwWfUJiFSPqkkNeY0WOm5kI387/5K837Fv/5FBQaAmMbhOf2aMfmbfo129LFu1hf0H\njhbxGwTnNBQ0CD9VOTVbV6T6Vc0Tgddooa3b3+u/cC1ZvomXX93j+3vr62sHVPIE9wXoD39wzPf3\n5qpJJKivr/UsBJcryL5O/I7912xdkepWNU8EXjnr7NIOQWv7OF1sS73mcHtbC71v3+Ja+8et5EO+\niqD5KM8vIjAEgcAY86Ix5sn0fytL9b1eo4UypR3GT7mzPyDkjqiprXUehlPsxTaf9rYWzj93HB+f\ndLtjraH2thbXtJZX0Tg/lOcXEShzasgY0whgrb2o2O9ymvm7pmPGoAJq2TIlGHILvHmlWHIvtqVe\nA/ep53Z4Fptb97jtH/K5ZPmmQTOiH9mwzbGDelhdDUno39ft8yIiZV2hzBgzBfgx8BapIDTfWvuc\ny74TcFmhzG2EUKYTs/aU2+jrc/+93FbmOmHUcD74sJujXT00NtRxdes5g8bdh7mymJvkzltd38t3\nLkQkXgpZoazcncUfAn8P/AD4FPCYMcZYawP1euYrkuYVBMD9CeDAoa68SxpWWnG17E5w3e2LSCHK\nHQheA35trU0Crxlj9gGfAHYG+RK3i/HLr+5h1g2P5P38sLoax5XKvDpPM6moUhSdCyJ7FrMbt1E9\nTukzBQgRyVXuQPB1YCLwTWNMMzASeCfol3gtFuNnRI/bcpVunad+F3APw+3zLy7oc26F8yD/JDIR\niZdyjxr6Z+A4Y8wm4H7g60HTQlCahd/HNzf5niTld93iMBR60XYrteFnEpmIxEtZnwistceArxb7\nPYVODsu2e+8h3tp8PZCaKTzrhkdonfNgf7mI7E7ioeoXGFZXWJxeu67TtdRFpfVxiMjQi+yEsszk\nsIlnjHZ8P99FtHn0CMC9XMTchev79x2qiVfdPX2sXdfZv4pZ3YTbBlVKdeL1BKNJZCKSK7KBIMMt\nTXTS6I/R3tbiOlEss7SAnyUdS5GKAqitCV6n+qbFT9A650E6t+3Nu45ChtddvyaRiUiuyAeCTFG0\nE0YNH7B95+6DLFu1xXWUz+49hwD3zuXsIaYzp0+kpoCLeK6zzWjXchFu3CbHeeX63e76xzc3qaNY\nRAaJfCDI2Lf/SKD9M6mhxoZax/cTiYGziEc1NRbeuLRX7N6Slal2u+tfu66T3x50roJa6AgkEalu\nka8+unZdp6+5A7ne3n2Ates6ubp1smOJh2Tyo0Vfnn1+Z+BA46SQWdxu6yQ73fW7DXMdP7aJ2+dd\nrKcBEXEU6UBQ7Pj+Jcs39ZeY7vjRFpyu03MWrg8cBNrbWlyDSz6NDXX09PYNqBHkd2EYt07i40Y2\nKgiIiKvIBoJCnwSyvWL3Mn7KnZ7pmnxBIJGAhvo6urt7GXvSSJIkWbH6F4xrHkkikWD3nkPU1db4\nXjsgsxZwLj8lJNzSRRoyKiJeIhkISjXTt68v//KV+SST0N3dS29fckDHbuZ713TM4GvXPeT7++pq\nawatK+x3YRitLywihYhkZ/FQzvR10utR5G7J8k2BLsRHu3p8DxPNddF5Exy3XzjlFN/fISLxE8lA\nUIpUR6L40aC+bN3+nus8hOwhr24T4IKUhHjyuR2O25/a/Jbv7xCR+IlkIChFqqMU8wL8aB49YtAC\n8JmKotn9D26F8IIEvV+9pj4CEQkukoGgFDN9y1VOOjNMNVMSo/vN79A0ssH35/0GvbXrOl3XYVAf\ngYh4iWQgyL3DzlQPzZ1dHIb2tpb+4/o9Xm56J8gdut+SEF79JiorISJeIhkIMpLJJL29fbz2xvtc\nMfehkkz68iNzZ//+yzfR3taSt8Bd7oXfqwSEU2lsP0Xn3IJLTU1CcwhExFMkA0Fm+Gjntr0kk6l6\nQfmWpyyV7GJ0AEsXXcqxN7/jWgUVBl/43Ub33D7/4v4g89KGa/uDgJ+ic27B5dPGvV0iIhDRQDCU\nw0fdJoZ59Vtkp2YyZa9ztbe1ON6551ufOd/xqyUtFLQUt4j4F8kJZUM5CiaRgLoJt9E8JlW0btc7\nB2mor+VYdx/jmkfy4ZHuQSmq7NXCnIIAuA/x9DtbuJoXsdeymyLhilwgWLuuk2F1NfT25l+bOAzJ\nZGrEUfaM5Ewpa7dZyjt3H6R1zoOeJajdLvhBZgv7nYEcNV5PRdX4+4qUW6RSQ5k7Qz8L1Fcir3IW\nmbLYuao95eOHaiiJhCtSgaDSSkuUUma+QS63obJxuhN26wjX/AiR0ohUaqja7wDdUh3VmvLxa/6c\nqb5LcYtIcJF6Iqj2O8BqD3SF0lORSLgi9UTgdmdYLcIOdGvXdbK445n+UUWZMtdREPenIpEwRSoQ\n5A6RTOBerK0SrOmYATivMOYkzFSHhmCKiJtIpYaA/uJtq+/6SkUEgUlnjGZNx4z+iqKQWiM4EwS8\nOrjHj20qW6rD78Q0EYmfSD0RZJRqhbJCnDBqOAcOdQ2YsLV2XSdNIxuo3ZPoT7mA85NAbU2Cs83o\nsk/20hBMEXETyUCQPVO3nMY1j+Rv518y4ALulnJxK0R3thnNSxuu9TxOGLl8LWMpIm4iGQiKXWe4\nmOO2znmQZ5/fySMbtnm2o9CFZsLK5WsIpoi4iVwfQSUUG1u2akvBwSjfHXhYuXwNwRQRN5F7Ioj6\n7OJ8d+Bh5vI1BFNEnETuiSCqnZuNDXW+7sBVTkFEyi1ygaDSL4jZw0izrbxjuq+7cRWZE5Fyi1wg\nKMXC9YWorUkw6cwxtLe1uO4zfmwTb22+vqhcvHL5IlJukeojWLuusyxDR9vbWnhq81ueC7w4LTBz\n+7yLgeJz8crli0g5RSYQlGsSmZ+776WLLuX8c8dV5WpgIhI/kQkE5RgtNOnMMYFSOLrwi0g1iEwf\nQTlGC6lDVkTiKDKBwO9oofa2lkEdrU5F4Zz20x2+iMRRWVNDxpgaYAXw+0AX8L+stb/281m3EgnD\n6mro60vmLeSmi7yIiLNy9xF8GWi01v43Y8x5wB3AdD8fzF2LQB20IiKlUe5A8HngXwGstc8ZY84N\n8mF10IqIlF65A8FI4EDW615jTJ21tsdh31qAd999tywNExGpBlnXzFq/nyl3IDgIjMh6XeMSBAA+\nAXDFFVeE3igRkSr0CeB1PzuWOxD8B3AZ8NN0H4FXTelfAFOBd4DeMrRNRKQa1JIKAr/w+4FEMpkM\nrzk5skYNTQISwCxr7bayNUBERAYpayAQEZHKE5kJZSIiEg4FAhGRmFMgEBGJuYqsPlpMKYpKYYx5\nkY/mTLxprZ01lO3xyxgzBbjdWnuRMeY0YBWQBF4BZltr+4ayfV5y2n4O8CiwPf323dba+4eude6M\nMcOAHwITgAbgr4CtROTcu7R/F9E5/7XAPYAhNUJxFqnBLKuIxvl3an8TAc5/RQYCiihFUQmMMY0A\n1tqLhrgpgRhjbgSuBD5Ib7oTWGCtfdIY8z1Sf4OHh6p9Xhzafg5wp7X2jqFrlW9fA/ZZa680xpwA\nvAj8PyJy7nFu/3eJzvm/DMBa+zljzEWk/t0niM75d2r/owQ4/5WaGhpQigIIVIqiAvw+8DvGmA3G\nmH9LB7MoeB24POv1ZOCp9M+PAReXvUX+ObX9j4wxTxtj/tkYM8Llc5XgAWBh1useonXu3dofifNv\nrX0EuCb98hRgDxE6/x7t933+KzUQOJaiGKrGFOBD4O+BLwLfAO6LQvuttQ8C3VmbEtbazPjiQ6Qe\nNyuSQ9u3AH9prb0AeAO4ZUga5oO19rC19lD6/6w/AxYQrXPv1P7InH8Aa22PMeZHwDJSv0Nkzj84\ntj/Q+a/UQBCkFEUleg2411qbtNa+BuwjXTIjYrJzoiOA3w5VQwrwsLX2hczPwB8MZWPyMcaMA/4d\nWG2t/QkRO/cO7Y/U+Qew1l4FnE4q3z48662KP/8wqP0bgpz/Sg0E/wFcCuCjFEUl+jqpfg2MMc2k\nnnDeGdIWFebFdM4R4EtA+OuFls7PjTEt6Z+nAS947TyUjDFjgA3ATdbaH6Y3R+bcu7Q/Suf/SmPM\nvPTLD0kF4ecjdP6d2v9QkPNfqemKh4FLjDHPki5FMcTtCeqfgVXGmE2kRh18PWJPNBk3APcYY+qB\nV0k9ckbFtUCHMeYY8C4f5VAr0XxgFLDQGJPJtV8HLI3IuXdq/18Ad0Xk/D8ErDTGPA0MA75F6pxH\n5d++U/t3EuDfv0pMiIjEXKWmhkREpEwUCEREYk6BQEQk5hQIRERiToFARCTmKnX4qMiQMMYsBz4H\n1AOnkSr+BvCP1tqVAb5nNfB/rLW/KX0rRUpLgUAki7V2NoAxZgLwpLX2MwV+1X8nNQdGpOIpEIj4\nkK6jsxw4m1RKdYm19qfGmD8AvkdqwfAjwFVAKzCa1Ozaz1lrK748gcSb+ghE/LkFeM5aOxm4CLjF\nGHMKqRm0f2OtPRdYCZxnrf1rYC/wRQUBiQI9EYj4czFQb4zJTNX/XeAs4F+A7xlj/ohUDfhHh6h9\nIgXTE4GIP7XATGvtZ9L9BlOAJ6y1a0nVfn8B+Dap9JFIpCgQiPjzb6QK2WGMGUuqIm6zMeZB4DPW\n2rtJpY/OSe/fg564JSIUCET8+Q7QZIzpBB4H/sJa+xap9XlvTa9R/dfA7PT+/5dUZ/H4IWmtSACq\nPioiEnN6IhARiTkFAhGRmFMgEBGJOQUCEZGYUyAQEYk5BQIRkZhTIBARiTkFAhGRmPv/POZCeneu\nXbsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0ca71b048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (6,6))\n",
    "ax = plt.axes()\n",
    "\n",
    "ph_test_predict = pd.DataFrame({'test': y_test.values, \n",
    "                                'predict': y_test_pred_gr_sugar}).set_index('test').sort_index()\n",
    "                                                                # set_index sets 'test' as the index\n",
    "                                                                # sort_index sorts by index \n",
    "\n",
    "ph_test_predict.plot(marker = 'o', ls = '', ax = ax)\n",
    "ax.set(xlabel = 'Test', ylabel = 'Predict', xlim = (0, 35), ylim = (0,35)); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A plot of the actual vs predicted `residual_sugar`.  There is some correspondence between the actual and predicted values, but since our model is likely overfitting, it did not generalize incredibly well to test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 (Optional) \n",
    "This question is optional as it requires an additional command line program (GraphViz) and Python library (PyDotPlus). GraphViz can be installed with a package manager on Linus and Mac. For PyDotPlus, either `pip` or `conda (conda install -c conda-forge pydotplus`) can be used to install the library. \n",
    "Once these programs are installed: \n",
    "* Create a visualization of the decision tree from question 3, where wine color was predicted and the number of features and/or splits are not limited. \n",
    "* Create a visualization of the decision tree from question 4, where wine color was predicted but a grid search was used to find the optimal depth and number of features. \n",
    "\n",
    "The decision tree from question 5 will likely have too many nodes to visualize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "from IPython.display import Image, display \n",
    "\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try: \n",
    "    import pydotplus\n",
    "    pydotplus_installed = True \n",
    "    \n",
    "except: \n",
    "    print('PyDotPlus must be installed to execute the remainder of the cells associated with this question.')\n",
    "    print('Please see the instrucions for this question for details.')\n",
    "    pydotplus_installed = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pydotplus.graphviz.Dot object at 0x000001A0CABEE208>\n"
     ]
    },
    {
     "ename": "InvocationException",
     "evalue": "GraphViz's executables not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-63b666d57587>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# View the tree image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'wine_tree.png'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\idp\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(path, f, prog)\u001b[0m\n\u001b[0;32m   1808\u001b[0m                 \u001b[1;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1809\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1810\u001b[1;33m                 \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1811\u001b[0m             )\n\u001b[0;32m   1812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\idp\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, path, prog, format)\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m                 \u001b[0mfobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1919\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\idp\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   1958\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1959\u001b[0m                 raise InvocationException(\n\u001b[1;32m-> 1960\u001b[1;33m                     'GraphViz\\'s executables not found')\n\u001b[0m\u001b[0;32m   1961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1962\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprog\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvocationException\u001b[0m: GraphViz's executables not found"
     ]
    }
   ],
   "source": [
    "# Tree from Question 3 \n",
    "\n",
    "if pydotplus_installed: \n",
    "    \n",
    "    # Create an output destination for the file \n",
    "    dot_data = StringIO()\n",
    "    \n",
    "    export_graphviz(dt, out_file = dot_data, filled = True)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "    print(graph) \n",
    "    \n",
    "    # View the tree image \n",
    "    filename = 'wine_tree.png'\n",
    "    graph.write_png(filename)\n",
    "    img = Image(filename = filename)\n",
    "    display(img)\n",
    "    \n",
    "else: \n",
    "    print('This cell not executed because PyDotPlus could not be loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7 \n",
    "* Import the iris data and examine the features. \n",
    "* We will be using all of them to predict species, but the species feature will need to be integer encoded. \n",
    "* Convert species feature to an integer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = os.sep.join(data_path + ['Iris_Data.csv'])\n",
    "data = pd.read_csv(filepath, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "data['species_le'] = le.fit_transform(data['species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8 \n",
    "* Use `StratifiedShuffleSplit` to split data into train and test sets that are stratifies by species. If possible, preserve the indices of the split for question 11 below.\n",
    "* Check the percent composition of each species level for both the train and test data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = list(data.columns[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strat_shuff_split = StratifiedShuffleSplit(n_splits = 1, \n",
    "                                           test_size = 0.3, \n",
    "                                           random_state = 42)\n",
    "\n",
    "# Get the index values from the generator \n",
    "train_idx, test_idx = next(strat_shuff_split.split(data[feature_cols], \n",
    "                                                   data['species_le']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = data.loc[train_idx, feature_cols]\n",
    "y_train = data.loc[train_idx, 'species_le']\n",
    "\n",
    "X_test = data.loc[test_idx, feature_cols]\n",
    "y_test = data.loc[test_idx, 'species_le']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THe percentage of each species in the training and test data sets are equally distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize = True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts(normalize = True).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9 \n",
    "* Fit a decision tree classifier with no set limits on maximum depth, features, or leaves. \n",
    "* Determine how many nodes are present and what the depth of tihs (very large) tree is. \n",
    "* Using this tree, measure the prediction error in the train and test `iris_data` sets. What do you think is going on here based on the differences in prediction error? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state = 42)\n",
    "dt = dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.tree_.node_count, dt.tree_.max_depth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = dt.predict(X_train)\n",
    "y_test_pred = dt.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def measure_error(y_true, y_pred, label): \n",
    "    return pd.Series({'accuracy': accuracy_score(y_true, y_pred),\n",
    "                      'precision': precision_score(y_true, y_pred), \n",
    "                      'recall': recall_score(y_true, y_pred), \n",
    "                      'f1': f1_score(y_true, y_pred)}, \n",
    "                      name = label)\n",
    "\"\"\"\n",
    "\n",
    "def measure_error_new(y_true, y_pred, label): \n",
    "    return pd.Series({'accuracy': accuracy_score(y_true, y_pred)},                  \n",
    "                      name = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_full_error = pd.concat([measure_error_new(y_train, y_train_pred, 'train'), \n",
    "                                   measure_error_new(y_test, y_test_pred, 'test')], \n",
    "                                  axis = 1)\n",
    "\n",
    "train_test_full_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the almost 10% difference in error rates, there is likely overfitting of our model to the training set due to the large number of nodes and depth relative to the small dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree predicts better on the training data than the test data, which is consistent with (mild) overfitting.  \n",
    "\n",
    "Also notice the perfect recall for the training iris_data. In many instances, this predicion difference is even greater than that seen here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, annot = True, fmt = 'd'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, y_test_pred)\n",
    "print (report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10 \n",
    "* Use grid search with cross validation, find a decision tree that performs well on the test iris_data set. Use a different variable name for this decision tree model than in question 9 so that both can be used in question 12. \n",
    "* Determine the number of nodes and the depth of this tree. \n",
    "* Measure the errors on the training and test sets as before and compare them to those from the tree in question 9. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'max_depth': range(1, dt.tree_.max_depth + 1, 2), \n",
    "              'max_features': range(1, len(dt.feature_importances_) + 1)}\n",
    "\n",
    "GR = GridSearchCV(DecisionTreeClassifier(random_state = 42), \n",
    "                  param_grid = param_grid, \n",
    "                  scoring = 'accuracy', \n",
    "                  n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GR = GR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of nodes and max depth of the tree: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GR.best_estimator_.tree_.node_count, GR.best_estimator_.tree_.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_gr = GR.predict(X_train)\n",
    "y_test_pred_gr = GR.predict(X_test)\n",
    "\n",
    "train_test_gr_error = pd.concat([measure_error(y_train, y_train_pred_gr, 'train'), \n",
    "                                 measure_error(y_test, y_test_pred_gr, 'test')], \n",
    "                                 axis = 1)\n",
    "train_test_gr_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These test errors are just as bad as the previous ones.  Both models are clearly overfitting the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11 \n",
    "* Re-split the `iris_data` into X and y parts, this time with species being the predicted (`y`) `iris_data`. *Note*: if the indices were preserved from the `StratifiedShuffleSplit()` output in question 8, they can be used again to split the `iris_data`. \n",
    "* Using grid search with cross validation, find a decision tree **regression model** that performs well on the test `iris_data` set. \n",
    "* Measure the errors on the training and test sets using mean squared error. \n",
    "* Make a plot of actual vs. predicted species. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dr = DecisionTreeRegressor().fit(X_train, y_train)\n",
    "\n",
    "param_grid = {'max_depth': range(1, dr.tree_.max_depth + 1, 2), \n",
    "              'max_features': range(1, len(dr.feature_importances_) + 1)}\n",
    "\n",
    "GR_reg = GridSearchCV(DecisionTreeRegressor(random_state = 42), \n",
    "                      param_grid = param_grid, \n",
    "                      scoring = 'neg_mean_squared_error',\n",
    "                      n_jobs = -1)\n",
    "\n",
    "GR_reg = GR_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GR_reg.best_estimator_.tree_.node_count, GR_reg.best_estimator_.tree_.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = GR_reg.predict(X_train)\n",
    "y_test_pred = GR_reg.predict(X_test)\n",
    "\n",
    "train_test_GRreg_error = pd.Series({'train': mean_squared_error(y_train, y_train_pred), \n",
    "                                    'test': mean_squared_error(y_test, y_test_pred)}, \n",
    "                                   name = 'MSE').to_frame().T\n",
    "\n",
    "train_test_GRreg_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of actual vs predicted species \n",
    "fig = plt.figure(figsize = (6,6))\n",
    "ax = plt.axes()\n",
    "\n",
    "ph_test_predict = pd.DataFrame({'test': y_test.values, \n",
    "                                'predict': y_test_pred}).set_index('test').sort_index()\n",
    "                                                               \n",
    "\n",
    "ph_test_predict.plot(marker = 'o', ls = '', ax = ax)\n",
    "ax.set(xlabel = 'Test', ylabel = 'Predict', xlim = (0, 3), ylim = (0,3)); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 12 *(Optional)*\n",
    "\n",
    "This question is optional as it requires an additional command line program (GraphViz) and Python library (PyDotPlus). GraphViz can be installed with a package manager on Linux and Mac. For PyDotPlus, either `pip` or `conda` (`conda install -c conda-forge pydotplus`) can be used to install the library.\n",
    "\n",
    "Once these programs are installed:\n",
    "\n",
    "* Create a visualization of the decision tree from question 9, where wine species was predicted and the number of features and/or splits are not limited.\n",
    "* Create a visualization of the decision tree from question 10, where wine species was predicted but a grid search was used to find the optimal depth and number of features.\n",
    "\n",
    "The decision tree from question 11 will likely have too many nodes to visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree from question 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree fit with cross validation from question 10. This tree is much shallower than the previous one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:idp]",
   "language": "python",
   "name": "conda-env-idp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
